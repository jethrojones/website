---
---

One of the crazy complaints people have about using AI in schools is a concern about whether or not we can trust the AI

The Single Most Important Lesson Iâ€™ve Learned about AI In Education

Not all lessons are created equal.

Some lessons we learn are small. They are little reminders along the way of what truly matters.

Other lessons are giant. They fundamentally change the course of our entire lives.

Over the past 15 years teaching educators about Automation and AI, this is the single most important lesson I've learned:

You have to use it to see if you can trust it. 

The more you use it, the better you can see what it is doing, and how it is working, and whether you can trust it. 

Every little thing you try, you get closer to understanding _what_ you can trust it for and what you can't. 

Will there be mistakes? Yes. 

Will you learn from those mistakes? Only if you're paying attention. 

I listened to a [podcast today](https://podcasts.apple.com/us/podcast/artificial-intelligence-artificial-or-intelligent/id1648696679?i=1000655864150) and this was one of their main complaints h/t [@bustedpencils](https://twitter.com/bustedpencils) - what if we can't trust the AI? If you weren't involved in it, why would you trust it? If you've never used it, why would you trust it? 

Trust is a spectrum, and you get to trust someone (or something) by interacting with it and experiencing it. 

Here's the reality. You're going to trust some sort of technology, and then that thing is going to let you down. Sometimes, you give up on that tool. Other times, you continue working with it to find a way to make it work better. 

At the bottom of ChatGPT, it says, "ChatGPT can make mistakes. Check important info." This begs the question, what is important? 

Perhaps we expect perfection when the tools we've been using for the last several decades have not been perfect either. 